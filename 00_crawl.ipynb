{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "anonymous-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "\n",
    "#import face_recognition\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-jason",
   "metadata": {},
   "source": [
    "## 爬立委資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ly.gov.tw/Pages/List.aspx?nodeid=109\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Connection': 'keep-alive'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "encoding = chardet.detect(response.content)['encoding']\n",
    "html_content = response.content.decode(encoding , errors='replace')\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_lists = []\n",
    "\n",
    "for a_tag in soup.find_all('a', href=True):\n",
    "    href = a_tag['href']\n",
    "    if \"/Pages/List.aspx?nodeid=\" in href:\n",
    "        page_lists.append(href)\n",
    "\n",
    "for page in page_lists:\n",
    "    print(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = \"https://www.ly.gov.tw\"\n",
    "start = 124\n",
    "end = start + 114\n",
    "\n",
    "# Lists to store the data\n",
    "names = []\n",
    "eng_names = []\n",
    "partys = []\n",
    "sessions = []\n",
    "genders = []\n",
    "photos = []\n",
    "\n",
    "# Directory to save images\n",
    "image_dir = \"legislator_images\"\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "for page in page_lists[start:end]:\n",
    "    url = link1 + page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract information\n",
    "    name = soup.find('div', class_='legislatorname').get_text(strip=True)\n",
    "    eng_name = soup.find('li', text=lambda x: x and '英文姓名' in x).get_text(strip=True).split('：')[1]\n",
    "    party = soup.find('li', text=lambda x: x and '黨籍' in x).get_text(strip=True).split('：')[1]\n",
    "    session = soup.find('li', text=lambda x: x and '屆別' in x).get_text(strip=True).split('：')[1]\n",
    "    gender = soup.find('li', text=lambda x: x and '性別' in x).get_text(strip=True).split('：')[1]\n",
    "    photo_url = soup.find('img', class_='img-responsive')['src']\n",
    "    \n",
    "    # Store the information\n",
    "    names.append(name)\n",
    "    eng_names.append(eng_name)\n",
    "    partys.append(party)\n",
    "    sessions.append(session)\n",
    "    genders.append(gender)\n",
    "    photos.append(photo_url)\n",
    "    \n",
    "    # Save the photo\n",
    "    \n",
    "    photo_filename = os.path.join(image_dir, photo_url.split('/')[-1])    \n",
    "    with open(photo_filename, 'wb') as f:\n",
    "        f.write(requests.get(link1 + photo_url).content)\n",
    "        print(link1 + photo_url)\n",
    "    \n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'English Name': eng_names,\n",
    "    'Party': partys,\n",
    "    'Session': sessions,\n",
    "    'Gender': genders,\n",
    "    'Photo Filename': [photo.split('/')[-1] for photo in photos]\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('legislators_info.csv', index=False)\n",
    "\n",
    "print(\"Data extraction and image saving complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-people",
   "metadata": {},
   "source": [
    "## 動態生成分類字典，處理所有出現的黨派和性別組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "\n",
    "# 讀取CSV文件，Name, English Name, Session, Gender, Photo Filename, Party\n",
    "df = pd.read_csv('legislators_info.csv')\n",
    "\n",
    "image_dir = \"legislator_images\"\n",
    "\n",
    "classified_images = {}\n",
    "\n",
    "# 分類圖像\n",
    "for _, row in df.iterrows():\n",
    "    party = row['Party']  \n",
    "    gender = row['Gender']\n",
    "    photo_filename = row['Photo Filename']\n",
    "    \n",
    "    category = f\"{party}_{gender}\"\n",
    "    \n",
    "    if category not in classified_images:\n",
    "        classified_images[category] = []\n",
    "    \n",
    "    image_path = os.path.join(image_dir, photo_filename)\n",
    "    if os.path.exists(image_path):\n",
    "        classified_images[category].append(image_path)\n",
    "\n",
    "aligned_faces_dir = \"aligned_faces\"\n",
    "os.makedirs(aligned_faces_dir, exist_ok=True)\n",
    "\n",
    "# 複製圖片到相關目錄\n",
    "for category, images in classified_images.items():\n",
    "    category_dir = os.path.join(aligned_faces_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    \n",
    "    for image_path in images:\n",
    "        # 複製img\n",
    "        image_name = os.path.basename(image_path)\n",
    "        destination_path = os.path.join(category_dir, image_name)\n",
    "        shutil.copy(image_path, destination_path)  # 使用 shutil.copy 进行复制"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
